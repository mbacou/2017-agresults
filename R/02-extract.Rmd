# Data Codebook

All results are available in **STATA format** on [Huddle](https://abtassociates.huddle.com/workspace/734056/files/#/folder/1170295/list). The next section shows summary statistics for a sample of indicators.

STATA files are organized by country, by source, and by periodicity:

- `2017-agresults-{ISO3}-biovars.dta` --  
  1970-2000 baseline bioclimatic indicators (source: WorldClim), altitude and slope (source: SRTM)
- `2017-agresults-{ISO3}-traveltime.dta` --  
  travel time to nearest market (5 market sizes) (source: IFPRI/HarvestChoice)
- `2017-agresults-{ISO3}-soil.dta` --  
  soil organic carbon content and most probable soil class (source: SoilGrids)
- `2017-agresults-{ISO3}-monthly.dta` --  
  2015-2017 monthly bioclimatic indicators (source: FEWSNET/USGS/MODIS)
- `2017-agresults-{ISO3}-dekadal.dta` --  
  2015-2017 dekadal bioclimatic indicators (source: FEWSNET/USGS/MODIS)

All extracted indicators are listed below. A complete codebook is on [Huddle](https://abtassociates.huddle.com/workspace/734056/files/#/2978247).


```{r, eval=F}

lbl <- rbind(data.table(varCode=names(pts), varLabel=pts.lbl),
  unique(fews, by="varCode"), afsis, 
  data.table(varCode=paste0("bio", 1:19), varLabel=bio.lbl), fill=T)
fwrite(lbl, "./out/2017-agresults-GIS_codebook.csv")
# Made corrections by hand
lbl <- fread("./out/2017-agresults-GIS_codebook.csv")
lbl[, varCode := tolower(varCode)]

```

```{r}

kable(lbl[, .(
  Variable=varCode, 
  Description=varLabel,
  Period=period, Unit=unit, Start=start, End=end, Resolution=res)],
  align="llcclccc", caption="Codebook of Extracted Variables")

```


# Data Summaries

Below are summary graphs for a sample of indicators[^violin]. All estimates are at surveyed household locations (after imputing missing/invalid locations as described in [Section 1](./index.html)).

[^violin]: The *violin* plots in this document show **median** line in **red**, **mean** line in **green**, and the **blue** region is the inferred **95% confidence interval** of the mean.


```{r extract, eval=FALSE}

# Limit to whatever locations are in `pts`
iso3 <- c("KEN", "NGA", "UGA")
nga.pts$ISO3 <- "NGA"
ken.pts$ISO3 <- "KEN"
uga.pts$ISO3 <- "UGA"

pts <- rbind(
  nga.pts[, c("hhid", "ISO3", "adm0_name", "adm1_name", "adm2_name")], 
  ken.pts[, c("hhid", "ISO3", "adm0_name", "adm1_name", "adm2_name")],
  uga.pts[, c("hhid", "ISO3", "adm0_name", "adm1_name", "adm2_name")])

pts.lbl <- c("household id", "ISO3 country code",
  "GADM admin level-0", "GADM admin level-1", "GADM admin level-2")

bio.lbl <- c(
  "Annual Mean Temperature",
  "Mean Diurnal Range (Mean of monthly (max temp - min temp))",
  "Isothermality (BIO2/BIO7) (* 100)",
  "Temperature Seasonality (standard deviation *100)",
  "Max Temperature of Warmest Month",
  "Min Temperature of Coldest Month",
  "Temperature Annual Range (BIO5-BIO6)",
  "Mean Temperature of Wettest Quarter",
  "Mean Temperature of Driest Quarter",
  "Mean Temperature of Warmest Quarter",
  "Mean Temperature of Coldest Quarter",
  "Annual Precipitation",
  "Precipitation of Wettest Month",
  "Precipitation of Driest Month",
  "Precipitation Seasonality (Coefficient of Variation)",
  "Precipitation of Wettest Quarter",
  "Precipitation of Driest Quarter",
  "Precipitation of Warmest Quarter",
  "Precipitation of Coldest Quarter")

#####################################################################################
# Travel Times
#####################################################################################
pts.tt <- extract(tt, pts)
pts.tt <- data.table(cbind(pts@data, pts.tt))
rm(tt)

# Export to STATA (1 file per country)
pts.tt.lbl <- c(pts.lbl, c(
  "travel time to 20K market (hrs)",
  "travel time to 50K market (hrs)",
  "travel time to 100K market (hrs)",
  "travel time to 250K market (hrs)",
  "travel time to 500K market (hrs)"))

for(i in iso3) write.dta(
  setattr(pts.tt[ISO3==i], "var.labels", pts.tt.lbl),
  paste0("./out/2017-agresults-", i, "_traveltime.dta"), 
  convert.factors="string", version=12L)

#####################################################################################
# AfSIS/SoilGrids
#####################################################################################
# Use REST API at https://rest.soilgrids.org/
# Note that `rjson` is required (`jsonlite` won't do)
library(rjson)
library(sp)
# Test 2 points, could also add aluminum concentration `ALUM3S`
r <- REST.SoilGrids(c("ORCDRC","TAXNWRB"))
# => lots of random errors to return just 100 point batches
tmp <- over(r, pts[1:2,])

# Query SoilGrids API in batches of 100 points (73 batches)
# anything bigger seems to error out. Batch #11 errors individually.
tmp <- lapply(seq(1, nrow(pts), 100)[21:30], 
  function(x) {
    df <- over(r, pts[x:min((x+99), nrow(pts)),])
    df <- df[, c(3:9, 128, 145:146)]
    return(df)
  })

# Test and log bug on GitHub with NA values returned below
tmp <- pts[pts$hhid %in% c(10418, 110421),])


###############################################
# SoilGrids API is a little slow for over 7,000 points, can we extract from disk
# instead, and then post-process NA and invalid values?
tmp <- lapply(1:nrow(afsis), function(x) {
  r <- raster(afsis[x, raster])
  res <- extract(r, pts)
  cat("done", x, "\n")
  return(res)
})
  
pts.soil <- data.table(do.call(cbind, tmp))
setnames(pts.soil, tolower(afsis$varCode))
pts.soil <- data.table(cbind(pts@data, pts.soil))

# Post-process
summary(pts.soil)
# => looks OK
# What's the codification for `taxnwrb_250m_ll`
# This is available in rgdal::GDALinfo(afsis[, last(raster)])
# Use column MINIMUM as integer
afsis.lbl <- fread("ftp://ftp.soilgrids.org/legends/TAXNWRB.txt")
setkey(afsis.lbl, MINIMUM)
setkey(pts.soil, taxnwrb_250m_ll)
pts.soil[afsis.lbl, taxnwrb_250m_class := i.NAME]
pts.soil[, .N, by=taxnwrb_250m_class]
#            taxnwrb_250m_class    N
#  1:                        NA    2
#  2:           Haplic Acrisols 3217
#  3:            Vetic Acrisols    4
#  4:         Aluandic Andosols  185
#  5:        Ferralic Arenosols   44
#  6:       Hypoluvic Arenosols    3
#  7:        Ferralic Cambisols   74
#  8:          Haplic Cambisols  184
#  9:  Haplic Cambisols (Humic)    1
# 10:         Haplic Ferralsols  453
# 11:         Umbric Ferralsols    6
# 12:           Mollic Gleysols    1
# 13:          Haplic Leptosols    1
# 14:          Lithic Leptosols    4
# 15:         Rendzic Leptosols    3
# 16:           Haplic Lixisols 1189
# 17:           Haplic Luvisols  804
# 18: Haplic Luvisols (Chromic)   19
# 19:           Vertic Luvisols    6
# 20:  Haplic Nitisols (Rhodic)  893
# 21:          Haplic Phaeozems    1
# 22:           Luvic Phaeozems   43
# 23:             Aric Regosols    6
# 24:          Calcic Vertisols   17
# 25:          Haplic Vertisols  139
# 26: Haplic Vertisols (Eutric)    1

# Which 2 points are NA?
pts.soil[is.na(taxnwrb_250m_class), hhid]
# [1] 110418 110421 (Nigeria)
tmap_mode("view")
tm_shape(pts[pts$hhid %in% c(10418, 110421),]) + tm_dots()
# => TODO they are in a water body, we should move them


# Export to STATA (1 file per country)
pts.soil.lbl <- c(pts.lbl, afsis[, varLabel], "soil class based on the WRB (label)")

for(i in iso3) write.dta(
  setattr(pts.soil[ISO3==i], "var.labels", pts.soil.lbl),
  paste0("./out/2017-agresults-", i, "_soil.dta"), 
  convert.factors="string", version=12L)

#####################################################################################
# WorldClim Biovars
#####################################################################################
# Download tile and extract single point data, tiles are cached locally
# For Nigeria we need tiles #26 "bio1_26"
# For Kenya we need tiles #27 and #37 "bio1_27"
# For Uganda we need tiles #27
# Each of the 19 bioclim variables is available in a .bil raster
vars <- paste0("bio", 1:19)

# Nigeria (#26)
nga.wc <- lapply(vars, function(x) {
  r <- raster(paste0("~/Projects/hc-data/WorldClim_0.5/", x, "_26.bil"))
  tmp <- extract(r, pts[pts$ISO3=="NGA",])
  tmp <- data.table(tmp)
  setnames(tmp, x)
  return(tmp)
})

# Combine all vars
nga.wc <- do.call(cbind, nga.wc)
nga.wc <- cbind(pts@data[pts$ISO3=="NGA",], nga.wc)

# Kenya (#27, #37)
ken.wc <- lapply(vars, function(x) {
  r27 <- raster(paste0("~/Projects/hc-data/WorldClim_0.5/", x, "_27.bil"))
  r37 <- raster(paste0("~/Projects/hc-data/WorldClim_0.5/", x, "_37.bil"))
  tmp27 <- extract(r27, pts[pts$ISO3=="KEN",])
  tmp37 <- extract(r37, pts[pts$ISO3=="KEN",])
  tmp <- data.table(rowMeans(cbind(tmp27, tmp37), na.rm=T))
  setnames(tmp, x)
  return(tmp)
})

# Combine all vars
ken.wc <- do.call(cbind, ken.wc)
ken.wc <- cbind(pts@data[pts$ISO3=="KEN",], ken.wc)

# Uganda (#26, #27, #36, #37)
uga.hh[Y_imp==min(Y_imp), respon_id]
uga.hh[Y_imp==max(Y_imp), respon_id]
uga.hh[X_imp==min(X_imp), respon_id]
uga.hh[order(-X_imp), respon_id][1:4]
tmp <- coordinates(uga.pts[uga.pts$hhid==2746,])
tmp <- getData("worldclim", var="bio", res=.5, lon=tmp[1], lat=tmp[2],
  path="~/Projects/hc-data/WorldClim_0.5")

tmap_mode("view")
tm_shape(raster("~/Projects/hc-data/WorldClim_0.5/bio1_27.bil")) + tm_raster() +
tm_shape(raster("~/Projects/hc-data/WorldClim_0.5/bio1_37.bil")) + tm_raster() +  
  tm_shape(uga.pts, is.master=TRUE) + tm_dots()

uga.wc <- lapply(vars, function(x) {
  r26 <- raster(paste0("~/Projects/hc-data/WorldClim_0.5/", x, "_26.bil"))
  r27 <- raster(paste0("~/Projects/hc-data/WorldClim_0.5/", x, "_27.bil"))
  r36 <- raster(paste0("~/Projects/hc-data/WorldClim_0.5/", x, "_36.bil"))
  r37 <- raster(paste0("~/Projects/hc-data/WorldClim_0.5/", x, "_37.bil"))
  tmp26 <- extract(r26, pts[pts$ISO3=="UGA",])
  tmp27 <- extract(r27, pts[pts$ISO3=="UGA",])
  tmp36 <- extract(r36, pts[pts$ISO3=="UGA",])
  tmp37 <- extract(r37, pts[pts$ISO3=="UGA",])
  tmp <- data.table(rowMeans(cbind(tmp26, tmp27, tmp36, tmp37), na.rm=T))
  setnames(tmp, x)
  return(tmp)
})

# Combine all vars
uga.wc <- do.call(cbind, uga.wc)
uga.wc <- cbind(pts@data[pts$ISO3=="UGA",], uga.wc)

# Combine all countries
pts.wc <- rbind(ken.wc, nga.wc, uga.wc)
rm(ken.wc, nga.wc, uga.wc)


#####################################################################################
# Add SRTM Altitude and Slope
pts.srtm <- lapply(iso3, function(x) {
  r <- getData("alt", country=x, mask=F, path="~/Projects/hc-data/SRTM")
  tmp1 <- extract(r, pts[pts$ISO3==x,])
  slope <- terrain(r, opt=c("slope"), unit="degrees")
  tmp2 <- extract(slope, pts[pts$ISO3==x,])
  tmp <- data.table(cbind(tmp1, tmp2))
  setnames(tmp, c("alt", "slope"))
  return(tmp)
  })

pts.srtm <- rbindlist(pts.srtm)
pts.wc <- data.table(cbind(pts.wc, pts.srtm))
rm(pts.srtm)

# Export WorldClim and SRTM to STATA (1 file per country)
pts.wc.lbl <- c(pts.lbl, bio.lbl,
  "altitude (meter)", "slope (degree)")

for(i in iso3) write.dta(
  setattr(pts.wc[ISO3==i], "var.labels", pts.wc.lbl),
  paste0("./out/2017-agresults-", i, "_biovars.dta"), 
  convert.factors="string", version=12L)


#####################################################################################
# FEWSNET
#####################################################################################
# We need to iterate through all FEWS grids catalogued in `fews`, noting that missing 
# and invalid values will need extra correction. In general all r[r<0] should be NA, 
# aside from `ndvi_anom` et `et_anom` but that step takes time, maybe best to
# post-process (stretch and nil).
# Also checked that all FEWS layers are now unprojected (RFE grids are projected).
# Also note that the last available NDVI dekad #17 has not been corrected for cloud
# cover hence the large percentage of zero values. They should be converted to NA 
# (see e-mail from <mbudde@usgs.gov> 2017.07.11).
fews[status==F, raster := NA]
tmp.fews <- fews[status==T]
r <- raster(tmp.fews[1, raster], crs=tmp.fews[1, proj])
proj_aea <- proj4string(r)

tmp <- lapply(1:nrow(tmp.fews), function(x) {
  cat(tmp.fews[x, dest], "\n")
  r <- raster(tmp.fews[x, raster], crs=tmp.fews[x, proj])
  res <- extract(r, 
    if(proj4string(r)==proj_aea) spTransform(pts, proj4string(r)) else pts)
  return(res)
})
  
pts.fews <- data.table(do.call(cbind, tmp))
setnames(pts.fews, tmp.fews[, paste0(varCode, "_", format(date, "%Y%m%d"))])
pts.fews <- data.table(cbind(pts@data, pts.fews))

# Post-process steps
# 1) NDVI combine East and West extracts
pts.ndvi <- pts.fews[, .SD, .SDcols=c(1:5, which(names(pts.fews) %like% "ndvi"))]
pts.fews <- pts.fews[, .SD, .SDcols=which(!names(pts.fews) %like% "ndvi")]
pts.ndvi <- melt(pts.ndvi, id.vars=1:5)
pts.ndvi[, variable := str_replace(variable, fixed("ndvi_anom"), "ndvi-anom")]
pts.ndvi[, c("var", "zone", "date") := tstrsplit(variable, "_", fixed=TRUE)]
pts.ndvi[, date := as.Date(date, "%Y%m%d")]
pts.ndvi <- pts.ndvi[!is.na(value)]
pts.ndvi[, .N, by=.(hhid, var, date)][N>1]
pts.ndvi[, `:=`(variable=NULL, zone=NULL)]

# 2) NDVI stretch and nil cloud cover of last dekads
pts.ndvi[date=="2017-06-11", value := ifelse(value==0, NA, value)]
pts.ndvi[var=="ndvi", value := (value-100)/100]
pts.ndvi <- dcast(pts.ndvi, ...~var, value.var="value")
setnames(pts.ndvi, "ndvi-anom", "ndvi_anom")

# 3) Roll up daily PET to dekadal means
pts.pet <- pts.fews[, .SD, .SDcols=c(1:5, which(names(pts.fews) %like% "pet"))]
pts.fews <- pts.fews[, .SD, .SDcols=which(!names(pts.fews) %like% "pet")]
pts.pet <- melt(pts.pet, id.vars=1:5)
pts.pet[, c("var", "date") := tstrsplit(variable, "_", fixed=TRUE)]
pts.pet[, date := as.Date(date, "%Y%m%d")]
# make sure to match the other dekads (day -01, -11, -21)
pts.pet[, dekad := cut(mday(date), c(0,10,20,32), labels=c("d1", "d2", "d3"))]
pts.pet <- pts.pet[, .(value = mean(value, na.rm=T)), 
  by=.(hhid, ISO3, adm0_name, adm1_name, adm2_name, 
    year=year(date), month=month(date), dekad)]
pts.pet[, date := 
    as.Date(paste(year, month, dplyr::recode(dekad, d1=1, d2=11, d3=21), sep="-"))]
pts.pet[, `:=`(year=NULL, month=NULL, dekad=NULL)]
setnames(pts.pet, "value", "pet")

# 4) Move monthly `chirps` and `et_anom` vars to separate table
pts.monthly <- pts.fews[, .SD, .SDcols=c(1:5, which(
  names(pts.fews) %like% "chirps" | names(pts.fews) %like% "et_anom"))]
pts.fews <- pts.fews[, .SD, .SDcols=-which(
  names(pts.fews) %like% "chirps" | names(pts.fews) %like% "et_anom")]

pts.monthly <- melt(pts.monthly, id.vars=1:5)
pts.monthly[, variable := str_replace(variable, fixed("et_anom"), "et-anom")]
pts.monthly[, c("var", "date") := tstrsplit(variable, "_", fixed=TRUE)]
pts.monthly[, date := as.Date(date, "%Y%m%d")]
pts.monthly[, variable := NULL]
pts.monthly <- dcast(pts.monthly, ...~var, value.var="value")

# 5) Recombine all dekadal vars `pts.ndvi`, `pts.pet`, `pts.fews`
pts.fews <- melt(pts.fews, id.vars=1:5)
pts.fews[, c("var", "date") := tstrsplit(variable, "_", fixed=TRUE)]
pts.fews[, date := as.Date(date, "%Y%m%d")]
pts.fews[, variable := NULL]
pts.fews <- dcast(pts.fews, ...~var, value.var="value")

setkey(pts.fews, hhid, ISO3, adm0_name, adm1_name, adm2_name, date)
setkey(pts.ndvi, hhid, ISO3, adm0_name, adm1_name, adm2_name, date)
setkey(pts.pet, hhid, ISO3, adm0_name, adm1_name, adm2_name, date)
pts.dekadal <- pts.fews[pts.ndvi][pts.pet]

# 6) Forgot to nil NDVI invalid values: 201 - 255 
# TODO check how many grids have uncorrected cloud cover
pts.dekadal[(100*ndvi)+100 > 200, ndvi := NA]

# Export all FEWS results to STATA (1 file per country)
pts.dekadal.lbl <- c(pts.lbl, "date",
  "SSEBop actual evapotranspiration (ETa) (dekadal, mm)", 
  "FEWS rainfall estimates (RFE) (dekadal, mm)",
  "eMODIS TERRA smoothed normalized difference vegetation index (NDVI) (dekadal, -1,-1)",
  "eMODIS TERRA NDVI anomaly (dekadal, percent of normal)",
  "potential evapotranspiration (PET) (monthly, mm)")

for(i in iso3) write.dta(
  setattr(pts.dekadal[ISO3==i], "var.labels", pts.dekadal.lbl),
  paste0("./out/2017-agresults-", i, "_dekadal.dta"), 
  convert.factors="string", version=12L)

pts.monthly.lbl <- c(pts.lbl, "date",
  "CHIRPS v2 rainfall estimates (monthly, mm)", 
  "SSEBop evapotranspiration anomaly (monthly, percent of median)")

for(i in iso3) write.dta(
  setattr(pts.monthly[ISO3==i], "var.labels", pts.monthly.lbl),
  paste0("./out/2017-agresults-", i, "_monthly.dta"), 
  convert.factors="string", version=12L)

```

```{r pts-save, eval=FALSE}

rm(i, x, dir, url, tmp, log, pet, tmp1, tmp2, r, slope, m, vars)
save.image("./tmp/2017-agresults.RData")

```


## Bioclimatic Indicators

### 2015-2017 Period

```{r res-fews, fig.cap="Distribution of Last Period Bioclimatic Indicators at Household Locations across Nigeria States, Kenya Regions, and Uganda Regions."}

for (i in iso3) {
  if (i=="UGA") par(mfrow=c(1,1), las=2) else par(mfrow=c(1,2), las=0)
  pplot(rfe~adm1_name, pts.dekadal[ISO3==i & date=="2017-06-01"], 
    ylab="Dekadal Rainfall Estimate (mm, FEWSNET/RFE)", xlab=NA)
  pplot(chirps~adm1_name, pts.monthly[ISO3==i & date=="2017-05-15"], 
    ylab="Monthly Rainfall (mm, CHIRPS)", xlab=NA)
  pplot(ndvi~adm1_name, pts.dekadal[ISO3==i & date=="2017-06-01"], 
    ylab="NDVI (-1,1 index, eMODIS C6)", xlab=NA, ylim=c(-0.1,1))
  pplot(ndvi_anom~adm1_name, pts.dekadal[ISO3==i & date=="2017-06-01"], 
    ylab="NDVI Anomaly (percent of median, eMODIS C6)", xlab=NA, ylim=c(50,150))
  pplot(eta~adm1_name, pts.dekadal[ISO3==i & date=="2017-06-01"], 
    ylab="Actual Evapotranspiration (mm, dekadal, MODIS/SSEBop)", xlab=NA)
  pplot(I(pet/100)~adm1_name, pts.dekadal[ISO3==i & date=="2017-06-01"], 
    ylab="Potential Evapotranspiration (mm, daily, NOAA/GDAS)", xlab=NA)  
}

```

We note from the above charts that NDVI and NDVI Anomaly values should be corrected on the left tail (might want to set all NDVI values below -0.3 to NA). These only affect the last 3 dekads (mostly).

```{r}

# An aside on NDVI
kable(pts.dekadal[, .(
  `NDVI < -.3` = sum(ndvi < -0.3, na.rm=T),
  `NDVI Anomaly < 30%` = sum(ndvi_anom < 30, na.rm=T)), keyby=.(ISO3, date)][
    `NDVI < -.3` > 2 | `NDVI Anomaly < 30%` > 2],
  caption="Dekads with NDVI values below -0.3")

```

### Long-Term Normals

```{r res-wc, fig.cap="Distribution of Long-Term Precipitation and Temperature Seasonality at Household Locations across Nigeria States/Kenya Regions (1970-2000) Source: WorldClim v2."}

for (i in iso3) {
  if (i=="UGA") par(mfrow=c(1,1), las=2) else par(mfrow=c(1,2), las=0)
  pplot(I(bio4/100)~adm1_name, pts.wc[ISO3==i], 
    ylab="Temperature Seasonality (celsius, std. dev.)", xlab=NA)
  pplot(bio15~adm1_name, pts.wc[ISO3==i], 
    ylab="Precipitation Seasonality (mm, coeff of var.)", xlab=NA)
}

```

## Soil Characteristics

There seems to be an anomaly with 30 cm and lower depth estimates (only whole integer values). To be reported.

```{r res-afsis, fig.cap="Distribution of Soil Organic Carbon at Household Locations across States/Regions (permilles) Source: SoilGrids 250m."}

for (i in iso3) {
  if (i=="UGA") par(mfrow=c(1,1), las=2) else par(mfrow=c(1,2), las=0)
  pplot(orcdrc_m_sl1_250m_ll~adm1_name, pts.soil[ISO3==i], 
    ylab="Soil Organic Carbon (0 cm, permilles)", xlab=NA)
  pplot(orcdrc_m_sl4_250m_ll~adm1_name, pts.soil[ISO3==i], 
    ylab="Soil Organic Carbon (30 cm, permilles)", xlab=NA)
}

```

## Market Access

```{r res-tt, fig.cap="Distribution of Travel Times to Market at Household Locations across States/Regions (hrs). Source: IFPRI/HarvestChoice."}

for (i in iso3) {
  if (i=="UGA") par(mfrow=c(1,1), las=2) else par(mfrow=c(1,2), las=0)
  pplot(tt10_20k~adm1_name, pts.tt[ISO3==i], 
    ylab="Travel Time to 20K Market (hrs)", xlab=NA)
  pplot(tt10_100k~adm1_name, pts.tt[ISO3==i], 
    ylab="Travel Time to 100K Market (hrs)", xlab=NA)
}

```



